# ETL Pipeline для вакансий HH.ru

Проект представляет собой полноценный ETL пайплайн для сбора и анализа вакансий с API HH.ru с контейнеризацией в Docker. 



## Цель проекта

Создать программу для сбора данных о вакансиях, их обработки и подготовки к аналитике.

### Технологический стек

- **Python** - язык разработки (3.13 для ручного запуска, 3.11 в Docker)
- **Docker** - контейнеризация
- **SQLite** - реляционная база данных
- **Requests** - работа с HTTP API 
- **CSV/JSON** - форматы хранения данных
- **Logging** - логирование выполнения пайплайна
- **Pathlib** - кроссплатформенная работа с путями

### ETL Пайплайн состоит из 6 этапов:

1. **Extract** - получение данных через API HH.ru
2. **Convert** - преобразование из JSON в CSV
3. **Sort** - сортировка вакансий по дате создания
4. **Enrich** - обогащение данных (определение уровня позиции)
5. **Aggregate** - агрегация и статистика + сохранение в SQLite
6. **Partition** - партиционирование по датам и конкатенация



## Запуск

### Через Docker

```bash
docker-compose run --rm etl python src/run_etl.py "Вакансия"
# docker-compose run --rm etl python src/run_etl.py "Data Engineer"
# docker-compose run --rm etl python src/run_etl.py "Data Analyst"
```

### Ручной запуск:

```bash
pip install requests pandas
python src/run_etl.py "Вакансия"
```

### Просмотр результатов в базе данных:

```bash
python view.py
```



## Эволюция проекта

Проект начинался как учебное задание, но был усовершенствован. (по этой же причине среди файлов остались bash-скрипты, как 
демонстрация изменений)

### Рефакторинг архитектуры

- **Было**: Разрозненные bash-скрипты 
- **Стало**: Единый Python пайплайн с кроссплатформенной работой и Docker контейнеризацией

### Улучшения

- контейнеризация с Docker
- SQLite база данных
- Логирование в файл и консоль
- Обработка ошибок на каждом этапе  
- Четкая структура папок
- Сохранены оригинальные bash-скрипты

### Результат

Учебное задание превратилось в полноценный ETL пайплайн, демонстрирующий понимание полного цикла данных.